{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas `DataFrame`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1 `DataFrame`s: Basics and Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1 Pandas `DataFrame` Objects\n",
    "\n",
    "The `pd.DataFrame` class provides a data structure to handle 2-dimensional tabular data. `DataFrame`  objects are *size-mutable* and can contain mixed datatypes (e.g. `float`, `int` or `str`). All data columns inside a `DataFrame` share the same `index`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.1.1 Creating `DataFrame`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "name = [\"person 1\", \"person 2\", \"person 3\"]\n",
    "age = [23, 27, 34]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nested list with zip and pass column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=zip(name, age), columns=[\"Name\", \"Age\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create with `dict`. Keys will be column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"Name\": name, \"Age\": age})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create from ndarray (then all columns of same type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=np.random.random((4, 3)), columns=list(\"abc\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two dicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "math_grades_dict = {\n",
    "    'student1': 15,\n",
    "    'student2': 11,\n",
    "    'student3': 9,\n",
    "    'student4': 13,\n",
    "    'student5': 12,\n",
    "    'student6': 7,\n",
    "    'student7': 14,\n",
    "}\n",
    "chemistry_grades_dict = {\n",
    "    'student1': 10,\n",
    "    'student2': 14,\n",
    "    'student3': 12,\n",
    "    'student4': 8,\n",
    "    'student5': 11,\n",
    "    'student6': 10,\n",
    "    'student7': 12,\n",
    "    \"student8\": 5,  # <-- note the additional entry here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert them to Series Objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "series_math = pd.Series(math_grades_dict)\n",
    "series_chemistry = pd.Series(chemistry_grades_dict)\n",
    "print(series_chemistry.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the two Series Objects to create a Dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={'math grades': series_math, 'chemistry grades': series_chemistry}\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.1.2 What characterizes a `DataFrame` object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Attribute giving us the `shape` of the `DataFrame`. Similar to `np.array`.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# A method providing infos on the `DataFrame` and the data contained inside.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get some statistics.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`DataFrame`s are essentially composed of 3 components. Theses components can be accessed with specific data attributes.\n",
    "\n",
    "- Index (`df.index`)\n",
    "- Columns (`df.columns`)\n",
    "- Body (`df.values`)\n",
    "\n",
    "Index and Body like `Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.values.nbytes, df.index.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can call `head()` (or `tail()`) first, when having loaded data into a `DataFrame`.\n",
    "It is useful for checking if all data columns were loaded successfully.\n",
    "It will print the first (last) 5 columns of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "# Compare the `tail()` method\n",
    "# df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.1.3 Data Indexing and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download IRIS dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\n",
    "#    'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "#    names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"],\n",
    "#)\n",
    "\n",
    "df = pd.read_csv('iris.data', names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check if data looks alright: (petal - Bluetenblatt, sepal - Kelchblatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column is a `Series` object and can be accessed like with a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing multiple columns at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_sepal = df[[\"sepal length\", 'sepal width']]\n",
    "df_sepal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows with boolean mask. In this case all columns will be returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[ df[\"Name\"] == \"Iris-setosa\" ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Name\"] == \"Iris-setosa\"  # the boolean expression inside the [] is a `Series` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to visualize the data. First specify color encoding of the different flower species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "name_to_color = {\n",
    "    'Iris-setosa': \"lightblue\",\n",
    "    'Iris-versicolor': \"darkred\",\n",
    "    'Iris-virginica': \"orange\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make a plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def structured_multigrid_plot(df, axes):\n",
    "    from itertools import permutations\n",
    "\n",
    "    features = df.columns[:-1].values.tolist()\n",
    "    feature_perms = tuple(permutations(features, r=2))\n",
    "    feature_perms_index = tuple(permutations(range(len(features)), r=2))\n",
    "\n",
    "    # Along the diagonal we plot the histogram\n",
    "    for idx, f in enumerate(features):\n",
    "        for name in df[\"Name\"].unique():\n",
    "            df[df[\"Name\"] == name][f].plot.hist(\n",
    "                ax=axes[idx, idx],\n",
    "                label=name,\n",
    "                color=name_to_color.get(name),\n",
    "                alpha=0.5,\n",
    "                bins=10,\n",
    "            )\n",
    "        axes[idx, idx].set_xlabel(\"\")\n",
    "        axes[idx, idx].set_ylabel(\"\")\n",
    "        axes[idx, idx].legend()\n",
    "\n",
    "    # Scatter plot showing correlations between feature pairs.\n",
    "    for perm, (row, col) in zip(feature_perms, feature_perms_index):\n",
    "        colx, coly = perm\n",
    "        for name in df[\"Name\"].unique():\n",
    "            df[df[\"Name\"] == name].plot.scatter(\n",
    "                x=colx,\n",
    "                y=coly,\n",
    "                ax=axes[col, row],  # use transpose to have same x-scale in each column\n",
    "                xlabel=\"\",\n",
    "                ylabel=\"\",\n",
    "                c=name_to_color.get(name),\n",
    "            )\n",
    "\n",
    "    for idx, f in enumerate(features):\n",
    "        label = f + \" / cm\"\n",
    "        axes[idx, 0].set_ylabel(label)\n",
    "        axes[-1, idx].set_xlabel(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    4, 4, figsize=(20, 15)\n",
    ")  # petal - Bluetenblatt; sepal - Kelchblatt\n",
    "structured_multigrid_plot(df, axes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get row with specific *index value*. Remember that index values must be contained in `df.index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rows with slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[0::4].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rows with fancy indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[[0, 4, 8, 12, 16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access whole columns with the `loc` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[ :, ['petal length', 'petal width']].head()\n",
    "# Does not work with `iloc` method (since it wants `int` values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as\n",
    "df[[\"petal length\", \"petal width\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean masks can also be used with `.loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df[\"Name\"] == \"Iris-setosa\"].head()\n",
    "# This is the same as\n",
    "# df[df[\"Name\"] == \"Iris-setosa\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are situations where using `[]` and `loc[]` actually are semantically different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose we want to alter some values inside a `DataFrame`. We want to limit the changes to certain rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This is a working copy.\n",
    "df_tmp = df.copy()\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The followiong is an example for \"chained indexing\".\n",
    "This calls (df_tmp.__getitem__(slice(1, 3, 1))).__setitem__(\"sepal length\",  -1000.0)\n",
    "\n",
    "This will yield a warning. We have *no guarantees* that this will return a view such that the assignment will succeed. It cannot be easily predicted if we obtain a copy or a view. It depends on the mem-layout of the data inside the `DataFrame`. Pandas does not make any guarantees which mem-layout we actually have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_tmp[1:3][\"sepal length\"] = -1000.0\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a better way of handling the assignment. This calls `df_tmp.loc.__setitem__(slice(1, 3, 1), \"sepal length\")` and allows to deal with the assignment in single step (just *one* function call instead of two function calls)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_tmp.loc[1:3, \"sepal length\"] = -1000.0\n",
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For more details on the difference between using `[]` and the `loc` method see [this link](https://stackoverflow.com/questions/48409128/what-is-the-difference-between-using-loc-and-using-just-square-brackets-to-filte#52919794)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use combined boolean masks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "boolean_mask = (df[\"sepal length\"] > 6.0) & (df[\"petal length\"] > 1.0)\n",
    "df.loc[boolean_mask].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.1.4  A word on views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a DataFrame for some experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0, 20, (4, 2)), columns=list(\"AB\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a view on a slice of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_slice = df.loc[1:3, :]\n",
    "df_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[1, \"A\"] = -1000\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this change visible from the slice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make another change. But this time we change the dtype of the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[1, \"A\"] = -999.99\n",
    "df  # Note how *all* value in column \"A\" are now `float`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the slice? Can we see this change as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The column `\"A\"` of the original `DataFrame` is a Pandas `Series` object with `dtype = int64`. When we replace a value from this `Series` with a value which is also of type `int64` (or another integer type) the change with also be visible from the view.\n",
    "\n",
    "If we try to place a `float` value inside this `Series` the value is not converted into a `int64` but rather a new `float` array is generated. The `float` array contains all of the original values as `flaot`s and the new value. The `float` array replaces the array inside the `Series` with column index `\"A\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2 Reading data into a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pandas can import several common file formats:\n",
    "\n",
    "- `pd.read_csv`: Read in CSV spreadsheets (`.csv` suffix)\n",
    "- `pd.read_excel`: Read in MS Office spreadsheets (`.xls` and `.xlsx` suffix) \n",
    "- `pd.read_stata`: Read stata datasets (`.dta` suffix)\n",
    "- `pd.read_hdf`: Read HDF datasets (`.hdf` suffix)\n",
    "- `pd.read_sql`: Read from SQL database\n",
    "\n",
    "Other file formats are [supported](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1.2.1 Reading from a CSV file\n",
    "\n",
    "A very common way to generate a `DataFrame` is to read data from an external file. CSV files can be parsed with Pandas convenience function [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the file with Pandas and specify the delimiter symbol as well as the a symbol for the comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"iris-data.csv\", delimiter=\";\", comment='#').head()\n",
    "\n",
    "# original CSV-File from https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
    "# reformated for our use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can limit the number of imported columns by specifying those that we explicitly want to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_iris = pd.read_csv(\n",
    "    \"iris-data.csv\",\n",
    "    delimiter=\";\",\n",
    "    comment=\"#\",\n",
    "    usecols=[\"Name\", \"sepal length\", \"sepal width\"],\n",
    ")\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1.2.2 Playing with the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`DataFrames` offer multiple methods for altering the Index. Some of them are:\n",
    "\n",
    "- [`df.reset_index()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html): Reset the index and use default index.\n",
    "- [`df.set_index()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html): Set the index  using an existing column.\n",
    "- [`df.reindex()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html): Change current index with additional filling logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Download IRIS dataset\n",
    "df = pd.read_csv('iris.data', names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"])\n",
    "\n",
    "# Quick check if data looks alright\n",
    "df.head()\n",
    "#df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the current index and use default indexing scheme. The index will be made a regular column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.reset_index().head()  # By default this returns a new object (inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select another column as our index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_new = df.set_index(\"Name\")  # By default this returns a new object (inplace=False).\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_new.loc[\"Iris-versicolor\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same inplace\n",
    "df.set_index(\"Name\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with student grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "math_grades = {\n",
    "    'stud1': 15,\n",
    "    'stud2': 11,\n",
    "    'stud3': 9,\n",
    "    'stud4': 13,\n",
    "    'stud5': 12,\n",
    "    'stud6': 7,\n",
    "    'stud7': 14,\n",
    "}\n",
    "chemistry_grades = {\n",
    "    'stud1': 10,\n",
    "    'stud2': 14,\n",
    "    'stud3': 12,\n",
    "    'stud4': 8,\n",
    "    'stud5': 11,\n",
    "    'stud6': 10,\n",
    "    'stud7': 12,\n",
    "}\n",
    "\n",
    "df_grades = pd.DataFrame(\n",
    "    {\"math\": pd.Series(math_grades), \"chemistry\": pd.Series(chemistry_grades)}\n",
    ")\n",
    "\n",
    "df_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the index of the `DataFrame` to add additional rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = list(math_grades.keys()) + [\"stud8\", \"stud9\"]\n",
    "\n",
    "df_grades.reindex(new_index, copy=True)\n",
    "# As long as copy=False (default: True) a new object is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also choose a specific value to fill into places that orginate from introducing a new index.\n",
    "df_grades.reindex(new_index, fill_value=\"missing\", copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1.2.3 Performance implications of the `inplace` argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a huge field of data for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "column_names = list(string.ascii_lowercase)\n",
    "N_rows, N_columns = 500_000, len(column_names)\n",
    "data = np.ones((N_rows, N_columns))\n",
    "index = range(N_rows)\n",
    "\n",
    "pd.DataFrame(data=data, index=index, columns=column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the performance difference between inplace and not-inplace :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def reset_index_of_DataFrame(index, data, colnames, inplace=False):\n",
    "    df = pd.DataFrame(data=data, index=index, columns=colnames)\n",
    "    df.reset_index(inplace=inplace)\n",
    "    del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit reset_index_of_DataFrame(index, data, column_names, inplace=False)\n",
    "%timeit reset_index_of_DataFrame(index, data, column_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `inplace` argument is available for many methods that operate on `DataFrames`. For performance and memory efficiency reasons, it may be a good idea to pass `inplace=True`  to these methods.\n",
    "\n",
    "Please be aware that this change will persist and will possibly influence future calls to other functions and methods.\n",
    "\n",
    "Please always refer to the documentation of the method of interest and check the availability and the relevance of the `inplace` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0eda2afbb3fb8d74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **1.**  Erstellen Sie basierend auf den beiden folgenden Listen auf verschiedene Arten einen `pd.DataFrame`. Die Namen der Spalten sollen dabei `\"Zufallszahlen\"` (für `values1`) und `\"Countdown\"` (für `values2`) sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9bac619e1dddd08b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "values1 = np.random.randint(-10, 10, size=5)\n",
    "values2 = range(5, 0, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b00108c6e2e8109",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **2.**  Gegeben sind die beiden folgenden `pd.Series`. Konstruieren Sie aus diesen einen `pd.DataFrame` mit den Spaltennamen `\"alles\"` (für `s1`) und `\"gerade Zahlen\"` (für `s2`). Ersetzen Sie die dabei auftretenden `NaN` Werte mit `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(data=range(5), index=list('abcde'))\n",
    "s2 = pd.Series(data=range(0, 10, 2), index=list('acegi'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9515e98389352eb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **3.**  Wir laden den Iris-Datensatz mit Maßen verschiedener Pflanzen herunter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe9930f49aec0b80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#df_iris = pd.read_csv(\n",
    "#    'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "#    names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"],\n",
    "#)\n",
    "\n",
    "df_iris = pd.read_csv('iris.data', names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"])\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-049bf46453f9b0ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **4.**  Greifen Sie auf die Spalten `\"sepal length`\", `\"petal width\"` und `\"Name\"` gleichzeitig auf zwei verschiedene Arten zu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e58fa340306562d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **5.** Die Messungen zu `\"Iris-setosa\"` sind leider unbrauchbar. Ändern Sie alle Einträge in `df_tmp1` und `df_tmp2` mit Messdaten zur Untergattung `\"Iris-setosa\"` auf `nan` (nicht aber die Spalte mit dem Eintrag `\"Iris-setosa\"`). Nutzen Sie einmal sequenzielles Indizieren (`[cols][rows]`) und einmal die `.loc`-Methode. Prüfen Sie anschließend, ob die Änderungen jeweils wirksam geworden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp1 = df_iris.copy(deep=True)\n",
    "df_tmp2 = df_iris.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04f5d0e0c1819a61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##### **6.** Stellen Sie die Verteilung der Messwerte separat in Histogrammen dar. Achten Sie auf Achsenbeschriftung und inbesondere auf Angabe der Einheiten. Wie verändern sich die Abbildungen, wenn Sie die Anzahl der `bins` verändern?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2  `DataFrame`s: Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.1  Arithmetic operations on `DataFrame`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Mapping between Python operators and Pandas methods\n",
    "\n",
    "| Python operator | Pandas methods                   |\n",
    "|:---------------:|----------------------------------|\n",
    "|       `+`       | `add()`                          |\n",
    "|       `-`       | `sub()`, `subtract()`            |\n",
    "|       `*`       | `mul()`, `multiply()`            |\n",
    "|       `/`       | `truediv()`, `div()`, `divide()` |\n",
    "|       `//`      | `floordiv()`                     |\n",
    "|       `%`       | `mod()`                          |\n",
    "|       `**`       | `pow()`                          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "A = pd.DataFrame(np.random.randint(0, 20, (3, 2)), columns=list(\"AB\"))\n",
    "B = pd.DataFrame(np.random.randint(0, 20, (3, 3)), columns=list(\"BAC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices are aligned, no matter what the order is in both `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of columns do not match. We use `fill_value` to to be used inplace for the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A.add(B, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NumPy broadcasting rules apply for `DataFrame`s as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(10, size=(3, 4)), columns=list(\"wxyz\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row-wise operations are the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df - df.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `axis` argument if we want to operate on the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.sub(df[\"x\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indices will be aligned for these kind of operations. This means that data context is maintained which helps avoiding uncessary errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_slice = df.loc[0, ::2]\n",
    "df_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df - df_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply NumPy Ufuncs to a `DataFrame` object as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.exp(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns based on arithmetic with existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df[\"asdf\"] = np.sin(df[\"x\"] * df[\"y\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.2 `agg()`, `apply()` , `applymap()` and `transform()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pandas `DataFrame` and `Series` objects have several built-in method to operate on the data.\n",
    "\n",
    "- `agg()`: available for *both* `Series` and `DataFrame` objects\n",
    "- `apply()`: available for *both* `Series` and `DataFrame` objects\n",
    "- `transform()`: available for *both* `Series` and `DataFrame` objects\n",
    "- `applymap()` *only* available for `DataFrame` objects\n",
    "- `map()`: *only* available for `Series` objects\n",
    "\n",
    "*Note*: In what follows we will only deal with  `agg()`, `apply()`, `applymap()` and `transform()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_iris = pd.read_csv(\n",
    "#    'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "#    names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"],\n",
    "#)\n",
    "\n",
    "df_iris = pd.read_csv('iris.data', names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"])\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get a subset of the data columns\n",
    "data_columns = df_iris.columns[:-1]\n",
    "data_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [`agg()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html)\n",
    "\n",
    "```python\n",
    "DataFrame.agg(func=None, axis=0, *args, **kwds)\n",
    "```\n",
    "- *applies* a function (callable) along an `axis` of the `DataFrame`\n",
    "    - `axis=0`: `func` is applied to each column (a `Series` object). This is the default!\n",
    "    - `axis=1`: `func` is applied to each row\n",
    "- return type is inferred from `func`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method performs aggregation operations along a specified axis of a `DataFrame`. It can be passed multiple functions, e.g. in `list`.\n",
    "\n",
    "The return can be:\n",
    " - scalar : when Series.agg is called with single function\n",
    " - Series : when DataFrame.agg is called with a single function\n",
    " - DataFrame : when DataFrame.agg is called with several functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris[data_columns].agg(['sum', 'max', 'min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris[data_columns].agg(['sum', 'max', 'min'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_iris[data_columns].agg([np.mean, np.std], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [`apply()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html)\n",
    "\n",
    "```python\n",
    "DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwds)\n",
    "```\n",
    "- *applies* a function (callable) along an `axis` of the `DataFrame`\n",
    "    - `axis=0`: `func` is applied to each column (a `Series` object). This is the default!\n",
    "    - `axis=1`: `func` is applied to each row\n",
    "- return type is inferred from `func`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The return type of `func` determines the form of the result.\n",
    "\n",
    "`func` can operate on `Series` objects an perform operations that are supported by these types of objects (e.g. by means of the methods `.min()`, `.max()` or `.mean()`). \n",
    "- result can be a scalar value (e.g. `.sum()` which is an aggregation operation)\n",
    "- result can be another `Series` object\n",
    "\n",
    "`func` must not be a agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Operate on columns (axis=0): `x` inside the `lamdba` function are `Series` objects!\n",
    "result = df_iris[data_columns].apply(lambda x: x.mean(), axis=0)\n",
    "print(f\"The type of the output is {type(result)}\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Operate elementwise along all values in a row (axis=1).  The return type is another `DataFrame`.\n",
    "\n",
    "# This converts the units of all measured values from cm to mm.\n",
    "df_iris[data_columns].apply(lambda x: x * 10, axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "As an example for using the `agg()` and `apply()` functions we normalise the features (data_columns) of the IRIS dataset and plot the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Specify color encoding of the different flower species.\n",
    "name_to_color = {\n",
    "    'Iris-setosa': \"lightblue\",\n",
    "    'Iris-versicolor': \"darkred\",\n",
    "    'Iris-virginica': \"orange\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_raw(axes, df, data_columns):\n",
    "    for idx, (ax, f) in enumerate(zip(axes, data_columns)):\n",
    "        for name in df[\"Name\"].unique():\n",
    "            df[df[\"Name\"] == name][f].plot.kde(ax=ax, color=name_to_color.get(name))\n",
    "        ax.set_xlabel(f + \" / cm\")\n",
    "\n",
    "\n",
    "def plot_normalised(axes, df, data_columns):\n",
    "    df_agg = df[data_columns].agg([\"mean\", \"std\"])\n",
    "    df_normalised = df[data_columns].apply(\n",
    "        lambda x: (x - df_agg.loc[\"mean\"]) / df_agg.loc[\"std\"], axis=1\n",
    "    )\n",
    "    #     print(df_normalised.describe())\n",
    "    for idx, (ax, f) in enumerate(zip(axes, data_columns)):\n",
    "        for name in df[\"Name\"].unique():\n",
    "            df_normalised[df[\"Name\"] == name][f].plot.kde(\n",
    "                ax=ax, color=name_to_color.get(name)\n",
    "            )\n",
    "        ax.set_xlabel(f + \" (normalised)\")\n",
    "\n",
    "\n",
    "def adjust_xscale(axes):\n",
    "    from functools import reduce\n",
    "    from math import ceil, floor\n",
    "\n",
    "    xmin, xmax = reduce(\n",
    "        lambda a, b: (min(a[0], b[0]), max(a[1], b[1])),\n",
    "        (ax.get_xlim() for ax in axes),\n",
    "        (1000, -1000),\n",
    "    )\n",
    "    xmin, xmax = floor(xmin), ceil(xmax)\n",
    "    for ax in axes:\n",
    "        ax.set_xticks(range(xmin, xmax + 1, 2))\n",
    "        ax.set_xticklabels(range(xmin, xmax + 1, 2))\n",
    "        ax.set_xlim((0.9 * xmin, 1.05 * xmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_distributions(df):\n",
    "    fig, axes = plt.subplots(2, len(data_columns), figsize=(20, 10))\n",
    "\n",
    "    # plot data as-is\n",
    "    plot_raw(axes[0, :], df_iris, data_columns)\n",
    "    # plot normalised data\n",
    "    plot_normalised(axes[1, :], df_iris, data_columns)\n",
    "    # adjust the x scale for the raw data\n",
    "    adjust_xscale(axes[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_distributions(df_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Experiment: What happens when operating with `apply`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "N_rows, N_cols = 10_000, 500\n",
    "df = pd.DataFrame(\n",
    "    np.random.random((N_rows, N_cols)), columns=[f\"col{idx}\" for idx in range(N_cols)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Benchmark: Operate along the columns (axis=0) vs operating along the rows (axis=1)\n",
    "%timeit df.apply(lambda x: x ** 2, axis=0)\n",
    "%timeit df.apply(lambda x: x ** 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def dummy(x):\n",
    "    \"\"\"Dummy function to showcase how `apply` operates.\"\"\"\n",
    "    # Some code is needed here.\n",
    "    print(type(x), x.shape)\n",
    "    return x - x.mean()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.random.random((5, 3)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(dummy, axis=0)  # apply along the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.apply(dummy, axis=1)  # apply along the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### `applymap()`\n",
    "\n",
    "```python\n",
    "DataFrame.applymap(func, na_action=None)\n",
    "```\n",
    "\n",
    "- `func` is applied to each element in the `DataFrame`\n",
    "- `func` is supposed to return a scalar values as well\n",
    "- return type of `applymap()` is another (modified) `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We repeat the simple example of changing the units of the measured data from cm to mm.\n",
    "df_iris[data_columns].applymap(lambda x: x * 10).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### `transform()`\n",
    "\n",
    "```python\n",
    "DataFrame.transform(func, axis=0, *args, **kwargs)\n",
    "```\n",
    "\n",
    "`func` can either be\n",
    "- callable, e.g. `np.exp`\n",
    "- list-like, e.g. `[np.sin, np.cos]`\n",
    "- dict-like, e.g. `{\"sepal length\": np.sin,  \"petal length\": np.cos}`. Application is limited to columns names passed as keys to `dict`.\n",
    "- string, e.g. `\"sqrt\"`\n",
    "\n",
    "*Note*: This function *transforms*, i.e, when the input value is `Series` another (transformed) `Series` is returned. Returning a scalar value is not valid (resulting error message will be: `ValueError: Function did not transform\n",
    "`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_iris[data_columns].transform({\"sepal length\": np.cos, \"petal length\": np.sin}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.3 Performance considerations\n",
    "\n",
    "When operating on columns of a `DataFrame` or a `DataFrame` as a whole it is oftentimes faster to use a vectorised operations instead of column-/row-wise operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(100000, 3), columns=list(\"abc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%timeit df.apply(lambda x: x ** 2)\n",
    "%timeit df.applymap(lambda x: x ** 2)\n",
    "%timeit df ** 2\n",
    "%timeit (df.values ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.4 Grouping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Oftentimes items in a dataset can be grouped in a certain manner (e.g., if a column contains a value multiple times). The IRIS dataset, for instance, can  be grouped according the species of each flower.\n",
    "\n",
    "```python\n",
    "my_dataframe.groupby(by=[\"<column label>\"])\n",
    "```\n",
    "The `DataFrame` is split and entries are grouped according to the values in the column with `\"<column-label>\"`. Once the data  has been grouped operations can be conducted on the items of each group.\n",
    "\n",
    "*Note*: `DataFrame`s cannot only be [grouped](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) according to the entries of a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The return type of `groupby()` is *not* another `DataFrame` but rather a `DataFrameGroupBy` object. We can imagine this object to be a grouping of multiple `DataFrame`s.\n",
    "\n",
    "It is important to understand that such an object essentially is a special *view* on the original `DataFrame`. No computations have been carried out when generating it (lazy evaluation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2.4.1 `GroupBy` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#df_iris = pd.read_csv(\n",
    "#    'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "#    names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"],\n",
    "#)\n",
    "\n",
    "df_iris = pd.read_csv('iris.data', names=[\"sepal length\", \"sepal width\", \"petal length\", \"petal width\", \"Name\"])\n",
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We group the data according to the species of the flowers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species = df_iris.groupby(by=[\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `DataFrame.groupby()`  method is *not* another `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(type(grouped_by_species))\n",
    "print(grouped_by_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This data structure still knows about the `columns` that were present in the original `DataFrame`. We can use the `[<column-name>]` operation to access the columns with the correspoding label in each of the group members (subframes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This does *not* return a `DataFrame`\n",
    "grouped_by_species[\"sepal length\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform several types of aggregations on this data structure. Pandas will access the corresponding column of all subframes and apply the functions passed to the `agg()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species[\"sepal length\"].agg([np.min, np.mean, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Access the groups contained inside `DataFrameGroupBy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can iterate over the `DataFrameGroupBy` object where each subframe is returned as a `Series` of a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for (species, subframe) in grouped_by_species:\n",
    "    print(f\"{species} subframe has shape = {subframe.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `get_group` we can choose the subframe to obtain a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species.get_group(\"Iris-setosa\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Dispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Methods that are not directly implemented for the `DataFrameGroupBy` object are passed to the subframes and executed on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species[\"sepal length\"].describe()  # The return type is a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` method can also be called on the full object but the output would be rather hard to view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_species.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single methods are available as well. E.g. `mean()`, `std()` or `sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species.mean()  # The return type is a `DataFrame`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also provides a convenient way to plot data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.set_xlabel(\"sepal length / cm\")\n",
    "grouped_by_species[\"sepal length\"].plot.hist(alpha=0.5, ax=ax, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2.5 Aggregate, filter, transform, apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`DataFrameGroupBy` object support `aggregate()`, `filter()`, `transform()` and `apply()` operations.\n",
    "\n",
    "These methods can be efficiently used to implement a great variety of operations on grouped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [`aggregate()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.aggregate.html) (or simply `agg()`)\n",
    "\n",
    "```python\n",
    "DataFrameGroupBy.aggregate(func=None, *args, engine=None, \n",
    "                           engine_kwargs=None, **kwargs)\n",
    "```\n",
    "\n",
    "`func` can for example be ...\n",
    "- ... function (Python callable),\n",
    "- ... a string specifiying a function name (e.g. `\"mean\"`)\n",
    "- ...  list of functions or strings, e.g. `[\"std\", np.mean]`\n",
    "- ... `dict` of column labels and function to apply (e.g. `{'data1': np.mean}`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some common aggegrations within each subframe. The output of this method is another `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "group_agg = grouped_by_species.agg([np.min, np.max, np.mean, np.std])\n",
    "group_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this a bit better consider the following. Note that we limit the output to only one species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df_iris[df_iris.columns[:-1]].loc[df_iris[\"Name\"] == \"Iris-setosa\"].agg(\n",
    "    [np.min, np.max, np.mean, np.std]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting output looks somewhat complicated than what we are used to from `DataFrame`s so far. The column labels now are hierarchical due to the grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "group_agg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select which operations to apply on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species.agg({\"sepal length\": np.mean, \"petal length\": np.median})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [`filter()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.filter.html)\n",
    "\n",
    "A filtering operation allows to select/drop data based on certain criteria.\n",
    "\n",
    "```python\n",
    "DataFrameGroupBy.filter(func, dropna=True, *args, **kwargs)\n",
    "```\n",
    "\n",
    "- `func` must be applicable to a `DataFrame`.\n",
    "- `func` should have a `bool`ean return type and hence should either return `True` or `False`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument of the callable passed to `filter` can be treated like a regular `DataFrame` object.\n",
    "\n",
    "From all subframes we select only those with mean value of 'sepal length' > threshold. The return type of the `filter` function is a `DataFrame` object. The grouping is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_by_species.filter(lambda x: x[\"sepal length\"].mean() > 6).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [`transform()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.transform.html)\n",
    "\n",
    "```python\n",
    "DataFrameGroupBy.transform(func, *args, engine=None, engine_kwargs=None, **kwargs)\n",
    "```\n",
    "\n",
    "Transformations return a modified version of  the original `DataFrame` with transformed values.\n",
    "\n",
    "`func` is applied to each subframe (operating at one `Series` at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example we center each of the data on the group-wise mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def center_on_mean(x):\n",
    "    return x - x.mean()\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "ax1.set_xlabel(\"measured value / cm\")\n",
    "df_iris.plot.kde(ax=ax1)\n",
    "(grouped_by_species.transform(center_on_mean)).plot.kde(ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [`apply()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.GroupBy.apply.html)\n",
    "\n",
    "```python\n",
    "GroupBy.apply(func, *args, **kwargs)\n",
    "```\n",
    "\n",
    "`func` must take a `DataFrame` as argument and return a `DataFrame`, a `Series` or a scalar. The final result will be combined into a `DataFrame` or a `Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def compute_df_mean(x):\n",
    "    print(type(x))  # The input datatype is a `DataFrame`\n",
    "    x = x.mean()\n",
    "    print(type(x))  # Returns a `Series` object\n",
    "    x = x.mean()\n",
    "    print(type(x))  # Returns a scalar\n",
    "    return x\n",
    "\n",
    "\n",
    "species_all_mean = grouped_by_species.apply(compute_df_mean)\n",
    "print(f\"The output type of the `apply()` operation is: {type(species_all_mean)}\")\n",
    "species_all_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73c76efc1f6a89d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### **1.** Sehen Sie sich den \"Titanic\"-Datensatz an. Importieren diesen in einen `pd.DataFrame` mit dem Namen `df_titanic`. Importieren Sie nur die  Spalten `\"class\"`, `\"age\"`, `\"sex\"` und `\"survived\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f94006c4cb70f0ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### **2.** Welche Einträge gibt es in den Spalten `\"class\"` und `\"age\"`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81b48b8dc7fcb4d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### **3.** Wie hoch war die Überlebensrate erwachsener Passagiere der ersten, zweiten bzw. dritten Klasse? Nutzen Sie dazu unterschiedliche Ansätze, und zwar:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f758dcf14baf3c40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Selektion der passenden Werte mit `bool`eschen Masken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d5d735c250267a18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Gruppierung von `df_titanic` nach zwei dafür relevanten Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2d3d12dc813fdea6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Anwenden der `apply`-Methode mit einer selbst geschriebenen Funktion `survival_rate` auf die nach `\"class\"` gruppierten Werte"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cefc3971-aeeb-4bbe-8554-d6c3d1b35f36",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f04d301dc08dccf97d054bcfd4a8ab4",
     "grade": false,
     "grade_id": "cell-cd68cdd31c242df1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Traffic Fines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8097ac4e-15d7-4390-a96e-551a6656ac82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7451c937fba9ee7b45e6ddf952927015",
     "grade": false,
     "grade_id": "cell-027f88bb37f55652",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jupyterquiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9580a47-8a02-4ae7-b339-490f2ed64b31",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "790cbb156c0af4083c0dc7d2b7dda92a",
     "grade": false,
     "grade_id": "cell-327803a499b17ba0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4859b469-330d-42f4-814b-a492beac802c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b8648ae725ecff0b9feac7028139623d",
     "grade": false,
     "grade_id": "cell-e182d7264c5de3fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "> Where and when do people violate which rules of traffic in Aachen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eded40f-5681-4832-a48d-564a71e24280",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c565434016c08921820d016b923680ed",
     "grade": false,
     "grade_id": "cell-d99842247b3f5630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3e203-ab5e-4a9b-aebe-d2ab6f9aeca5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba622e8369e3388c86994ead80e6a64b",
     "grade": false,
     "grade_id": "cell-f338e5f51e023839",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(A)` Finding Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00fb56c-afb4-4860-a8f4-7d9100bbb1c2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb31bc6a6f8cc368bd3b1bd7f694e1e9",
     "grade": false,
     "grade_id": "cell-89aeb1f541b68360",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "> Where might we find data pertinent to answering this question?\n",
    "\n",
    "Collect at least three possible data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57002872-7023-44fe-b7d1-cab91ebf024a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32fc9f39d286dd1ba27a8f95cffe8731",
     "grade": true,
     "grade_id": "cell-5dbe6c66ea595298",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c027f620-939d-4488-9e48-e671168e3aeb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77e3dc584af692edf23eaa3177977d19",
     "grade": false,
     "grade_id": "cell-9d428db0d778be58",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": []
   },
   "source": [
    "<span style=\"display:none\" id=\"quiz1\">W3siYW5zd2VycyI6IFt7ImNvcnJlY3QiOiB0cnVlLCAiZmVlZGJhY2siOiAiU3RhZHQgQWFjaGVuIiwgImFuc3dlciI6ICJJbnN0aXR1dGlvbnMifSwgeyJjb3JyZWN0IjogdHJ1ZSwgImZlZWRiYWNrIjogImh0dHBzOi8vb2ZmZW5lZGF0ZW4uYWFjaGVuLmRlLyIsICJhbnN3ZXIiOiAiUG9ydGFscyJ9LCB7ImNvcnJlY3QiOiB0cnVlLCAiZmVlZGJhY2siOiAiaHR0cHM6Ly9vZmZlbmVkYXRlbi5hYWNoZW4uZGUvZGF0YXNldC9idXNzZ2VsZGVyLWZsaWVzc2VuZGVyLXZlcmtlaHItMjAyMS1kZXItc3RhZHQtYWFjaGVuIiwgImFuc3dlciI6ICJVUkkifSwgeyJjb3JyZWN0IjogdHJ1ZSwgImZlZWRiYWNrIjogImh0dHBzOi8vb2ZmZW5lZGF0ZW4uYWFjaGVuLmRlL2RhdGFzZXQvMTRhMGU3NWYtYjA0MC00MWQ3LTkxZjMtMmQzYzMzZDNlYTM1L3Jlc291cmNlL2RmZDZmZjhjLTQ2OWQtNDE2NC04OGJlLWNhMzhmOTMyYzE3Ni9kb3dubG9hZC8yMDIxX2J1c3NnZWxkZXItZmxpZXNzZW5kZXItdmVya2Voci1nZXNjaHdpbmRpZ2tlaXRzdWJlcnRyZXR1bmdlbi5jc3YiLCAiYW5zd2VyIjogIlVSTCJ9XSwgInR5cGUiOiAibWFueV9jaG9pY2UiLCAicXVlc3Rpb24iOiAiQ2xpY2sgaGVyZSB0byByZXZlYWwgcG9zc2libGUgZGF0YSBzb3VyY2VzIn1d</span><span style=\"display:none\" id=\"quiz2\">W3siYW5zd2VycyI6IFt7ImNvcnJlY3QiOiBmYWxzZSwgImFuc3dlciI6ICJwdWJsaWMgZG9tYWluIn0sIHsiY29ycmVjdCI6IGZhbHNlLCAiYW5zd2VyIjogImFsbCByaWdodHMgcmVzZXJ2ZWQifSwgeyJjb3JyZWN0IjogdHJ1ZSwgImFuc3dlciI6ICJEYXRlbmxpemVueiBEZXV0c2NobGFuZCBcdTIwMTMgTmFtZW5zbmVubnVuZyBcdTIwMTMgVmVyc2lvbiAyLjAgKGh0dHA6Ly93d3cuZ292ZGF0YS5kZS9kbC1kZS9ieS0yLTApIn0sIHsiY29ycmVjdCI6IGZhbHNlLCAiYW5zd2VyIjogIkRhdGVubGl6ZW56IERldXRzY2hsYW5kIFx1MjAxMyBaZXJvIFx1MjAxMyBWZXJzaW9uIDIuMCAoaHR0cHM6Ly93d3cuZ292ZGF0YS5kZS9kbC1kZS96ZXJvLTItMCkifV0sICJ0eXBlIjogIm11bHRpcGxlX2Nob2ljZSIsICJxdWVzdGlvbiI6ICJXaGF0IGlzIHRoZSBsaWNlbmNlIG9mIHRoZSBkYXRhIHNldCBmcm9tIHRoZSByZWNvbW1lbmRlZCBzb3VyY2U/In1d</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bdcde1-1491-4fd2-9820-8107dd7077f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8f0ac02ebd0636dbd4894c816c19a0f",
     "grade": false,
     "grade_id": "cell-3b0f4980dba116b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jupyterquiz.display_quiz(\"#quiz1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb0db22-5f39-42b4-9900-4d7d201ab207",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af8a0ed1c74a7a7c8bf1978922c27586",
     "grade": false,
     "grade_id": "cell-9208cb12baaeaa2d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jupyterquiz.display_quiz(\"#quiz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f5d78-793c-427e-a51c-60898726817b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f51f879de6333c73d1e085e137b38ab6",
     "grade": false,
     "grade_id": "cell-fb699e15bf68c18f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ead6bc-1e19-4abc-9a88-40b999605e32",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60226091aa5467679d0329ed0495f11b",
     "grade": false,
     "grade_id": "cell-f75607406cc73c28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc6cfc-5320-4236-a079-c3f0a64bc7be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34924ad63f59ef522d88d9fbd9225101",
     "grade": false,
     "grade_id": "cell-af4360a3329f066d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "We find the following properties of the dataset:\n",
    "* **description**: Traffic fines in the city of Aachen over the course of 2021\n",
    "* **file format**: csv\n",
    "* **encoding**: ISO-8859-1 (\"Latin 1\")\n",
    "* **columns**: `Tattag;Zeit;Tatort;Tatort 2;Tatbestand;Geldbu√üe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c25e50-8ad8-459e-94b0-e47ed96e65ec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1fdfb4a8c9acf070aef5e7d70c246337",
     "grade": false,
     "grade_id": "cell-d41d5fd9df89d3a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Column descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd38f8-7e76-467b-9746-75adfabb983a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3f73112cd5c91049eacd74831fc95d8",
     "grade": false,
     "grade_id": "cell-d41d5fd9df89d3aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "| Column name |  Meaning                   |  Format                  |  Example                     |\n",
    "|:-----------:|:--------------------------:|:------------------------:|:----------------------------:|\n",
    "| Tattag      | Day of the offense         | DD.MM.YYYY               | 03.04.2021                   |\n",
    "| Zeit        | Time of day of the offense | HH:MM                    | 04:47                        |\n",
    "| Tatort      | Location of the offense    | City(, street( number))  | Aachen, Schurzelter Str. 523 |\n",
    "| Tatort 2    | Additional location        | Direction / exact street | Fahrtrichtung Innenstadt     |\n",
    "| Tatbestand  | Index number of offense    | from [Bundeseinheitlicher Tatbestandskatalog](https://www.kba.de/DE/Themen/ZentraleRegister/FAER/BT_KAT_OWI/bkat_owi_09_11_2021.pdf)  | 141237 |\n",
    "| Geldbu√üe    | Fine amount in ‚Ç¨ | Integer | 15 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8c752-f931-4f6e-8863-2e3618f90125",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6baaad6b1ea27cf05b821904751b71b7",
     "grade": false,
     "grade_id": "cell-50a6b1f33b14a0b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510c03f-0b41-4261-8e9a-cb8ce9501b59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b1776e2d77215bedbe77d4fd34ce45c",
     "grade": false,
     "grade_id": "cell-962d725fcdc2a06b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(R)` Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e31ea-4623-4862-b45c-18d3882315af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfe3cb094813e928dfd2d02c6b324c3f",
     "grade": false,
     "grade_id": "cell-3abb5450b461c401",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "From the URL given above, import the full dataset and get an overview as well as information on the properties of the imported columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b41d8f-8fa2-485b-9269-bbfbdae832eb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c62f12a1c6ad5bd147446697ea35de29",
     "grade": true,
     "grade_id": "cell-b27fdedb63bef6de",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295eaef9-cd9a-4deb-b32f-bb0bfca30912",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18ff65cd4d9aed6a643722db7e2b27c1",
     "grade": true,
     "grade_id": "cell-f75ae76d0cc10e94",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3e3fc-c135-4af7-80aa-0d1e7d20d032",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "925f0c55a27cbc3b5aa189ef0faf83be",
     "grade": true,
     "grade_id": "cell-8c428ffdd441eefc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b302e2-9368-49c3-a14d-1944589270bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e48e76f7bf0ceaf9690183a1800f5de",
     "grade": false,
     "grade_id": "cell-5e31556bc4c024df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(A)` Tweaking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f38b22-2e48-4999-90a0-18580b6f9c93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6e0d76ab7b990c77fd5349a93daf9ba",
     "grade": false,
     "grade_id": "cell-9a07900d7a8149da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "To be able to more efficiently work with the data, choose suitable data types for each column. In particular, combine the day and time column into a *single* datetime column. You may do this by assigning a new column or cleverly importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bff71-2509-4c04-836c-98e5db58700b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "905e987473fc7e9f4ffb03c3743e559c",
     "grade": true,
     "grade_id": "cell-fa2d412eb00e342a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62501ca1-5257-4156-bb3b-1b4ae3a64118",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce95f62b190b9003c78faa1ef3486425",
     "grade": true,
     "grade_id": "cell-1bc4918fdb24617d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9774694-8f90-4f8a-bd8f-1228fe3151b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af23f0298249b6a4dd1f8180c2cfd76c",
     "grade": false,
     "grade_id": "cell-bf34d56ebcc809e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(T)` Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee764749-6139-4c19-8ea6-9470adcb97ae",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "062f55c2061542c7a0a72906db6531a4",
     "grade": false,
     "grade_id": "cell-940152f736a7a979",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Combine your efforts into a single function `import_traffic_data` that imports and tweaks data of traffic violations read from a data source (url or file) and returns a tweaked DataFrame. Then find and attempt to read in traffic violation data from other years (e.g. 2020) or contexts (e.g. parking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d727de-723f-41d6-bf0a-7408c01cbd71",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9af217ab4876ddce869ff8ca82511d88",
     "grade": true,
     "grade_id": "cell-8ddc5ae4afbaec83",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8772e4c-dccc-477b-82e6-9e9baeba5eac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a467aeda6107bcaee68ba2556ad36810",
     "grade": true,
     "grade_id": "cell-c3f5476d71d9ef6f",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976a132-f881-4df5-ace3-2b69509c5821",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9a0afe-18a9-4c14-9a52-9384d6776a33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "708e23f4b6d6d1250e0db87ea8cbcf40",
     "grade": false,
     "grade_id": "cell-8c183023d907effc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(R)` Basic fine statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76c69e-5e88-4c3d-afae-d2df1a805240",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7e57bc68d30b6700b2d873f592b03db",
     "grade": false,
     "grade_id": "cell-7bac1c25454d1945",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "What is the minimal, maximal, mean and median amount of the collected fines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f64828a-a068-4b46-85df-e1ed933cc387",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5c82f0c6230a703e90491ec6fc83364",
     "grade": true,
     "grade_id": "cell-d286daa05f313db2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151eb170-2f55-41b2-88d6-20d8b73ff661",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "715bbd19a9e0f1f5af948f9f963b4813",
     "grade": false,
     "grade_id": "cell-a085f538b984b0d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(A)` Unique `\"Tatbestand\"` values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc890c7-876c-40aa-afa0-5083c048b75f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e8e48c7d2576fd38ff1c4df65e4293b",
     "grade": false,
     "grade_id": "cell-999386d87b9581b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "What are the unique values for `\"Tatbestand\"` and how many often does each one occur? Make a suitable visualization. Consider that rare violations might not be of interest and could be subsumed unter an \"other\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824891f8-fb51-43d3-9784-104658bf8c43",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "308f4b28c9190d5db84d461a5efd3a09",
     "grade": true,
     "grade_id": "cell-2d92861cb5218ea4",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7225e49-f5e5-42e4-8676-1e38d1ae6446",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3a9d1220fe77659caa6bad1c4c6ac228",
     "grade": false,
     "grade_id": "cell-4d9fe8a6f40cee64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13c498-bcc1-4263-879a-8df15ffe1838",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2208a3db9478eeffb512491287204523",
     "grade": false,
     "grade_id": "cell-d2c9d26478b596c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(T)` Collected fines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf71ca8-39e1-43c8-ad70-199c6f196b8d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9944707441e9f7920dba84c38deeb47b",
     "grade": false,
     "grade_id": "cell-d2c9d26478b596c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Compute the collected fines total per hour of day and visualize the results in a suitable manner. Perform the same analysis for grouping by month of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938373d-775a-4cc0-a9d4-419959778a88",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bfece772d22c7afb6101e58e836e499",
     "grade": true,
     "grade_id": "cell-3d4b85f24073d46c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12031c4d-1190-4a70-aea9-d05d59dca34d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "428266130cdb5a743050ac3b7b1c1400",
     "grade": true,
     "grade_id": "cell-7d6524a82a19a3eb",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1705ce-fbe3-40ca-a9a0-12adf1035202",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b1fd4f0edc4c6b50a1f7774ae3ebd3f",
     "grade": false,
     "grade_id": "cell-47eeedacf3b85934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### `(T)` Perennial violations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717f409d-e5ce-41a5-92f8-43abfde12a59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8600650da414b418c224bd1ebae57d7d",
     "grade": false,
     "grade_id": "cell-d5ce9929053c4905",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "What are the offence encodings that occur in *every* month of the year and how many of these are observed every month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515c429-4e28-4d17-a09e-60daa57a2b34",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06c777e757ed89331d3dc816f6b523e5",
     "grade": true,
     "grade_id": "cell-3e0afce0fae5ad21",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
